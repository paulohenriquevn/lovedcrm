# Story 3.2: Lead Analytics & Advanced Insights - Technical Refinement

**Refinement Date**: 2025-08-12  
**exec-refine Process**: Completed with 95%+ confidence  
**Foundation**: Story 3.1 ✅ Complete (LeadScoringService, DeduplicationService, AssignmentService)  
**Target**: Story 3.3 (UX Polish) - Bridge gap with intelligence layer

## Executive Summary

**Story 3.2** transforms structured data from Story 3.1's ML scoring system into **actionable business intelligence** through executive dashboards, behavioral analytics, smart alerts, and advanced reporting capabilities.

**Business Value:**

- **CFO**: ROI visibility - dashboards show exactly where R$ 200k+ are blocked and why
- **CTO**: Analytics engine + real-time insights + performance optimization + org-specific intelligence
- **PM/PO**: Product metrics revealing funnel bottlenecks + lead behavior analysis + conversion patterns
- **Stakeholders**: "Business Intelligence for leads" - analytics driving strategic decisions

## Foundation Analysis

### ✅ Existing Infrastructure (Story 3.1 Complete)

**Backend Services:**

- `api/services/crm_lead_scoring_service.py`: 6-factor ML scoring (0-100) with transparent breakdown
- `api/services/crm_lead_deduplication_service.py`: Fuzzy matching with 85%+ accuracy
- `api/services/crm_lead_assignment_service.py`: 3 strategies (round-robin, workload-balanced, score-based)

**Database Foundation:**

- `leads` table: Complete with `lead_score`, `score_factors`, stage tracking, organization isolation
- `audit_logs` table: Full audit trail for all lead changes and stage transitions
- Performance: 38 tables + 139+ indexes, < 50ms query performance validated

**Frontend Components:**

- `components/crm/lead-score-display.tsx`: Visual scoring system implemented
- shadcn/ui: 33+ components available (cards, tables, charts, badges)
- Recharts 2.15.4: Available for dashboards and data visualization
- TanStack Query: Data fetching and caching with organization isolation

**Technical Stack:**

- Backend: FastAPI 0.111.1 + SQLAlchemy 2.0.23 + PostgreSQL + Redis 5.0.1
- Frontend: Next.js 14 + TypeScript + shadcn/ui + Recharts + date-fns 4.1.0
- Multi-tenancy: organization_id isolation + X-Org-Id header validation

## Technical Specification

### 1. Database Schema Enhancements

**New Tables Required:**

```sql
-- Lead behavior tracking for engagement analytics
CREATE TABLE lead_behavior_tracking (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,
    lead_id UUID NOT NULL REFERENCES leads(id) ON DELETE CASCADE,

    -- Behavior metrics
    interaction_count INTEGER DEFAULT 0,
    last_interaction_at TIMESTAMP WITH TIME ZONE,
    engagement_score DECIMAL(5,2) DEFAULT 0.00,

    -- Stage timing analysis (seconds)
    time_in_lead_stage INTEGER DEFAULT 0,
    time_in_contact_stage INTEGER DEFAULT 0,
    time_in_proposal_stage INTEGER DEFAULT 0,
    time_in_negotiation_stage INTEGER DEFAULT 0,

    -- Analytics metadata
    behavioral_flags JSONB DEFAULT '{}',
    calculated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- Performance indexes
    INDEX idx_lead_behavior_org_id (organization_id),
    INDEX idx_lead_behavior_lead_id (lead_id),
    INDEX idx_lead_behavior_engagement (organization_id, engagement_score DESC)
);

-- Aggregated analytics events for performance
CREATE TABLE analytics_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,

    -- Event metadata
    event_type VARCHAR(50) NOT NULL,    -- 'conversion_rate', 'stage_transition', 'score_change'
    event_date DATE NOT NULL,

    -- Aggregated metrics
    metric_value DECIMAL(12,4) NOT NULL,
    metric_metadata JSONB DEFAULT '{}',

    -- Reference data
    entity_type VARCHAR(50),     -- 'lead', 'stage', 'source'
    entity_id VARCHAR(255),      -- specific ID or name

    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    -- Analytics performance indexes
    INDEX idx_analytics_org_date (organization_id, event_date),
    INDEX idx_analytics_type_date (event_type, event_date),
    INDEX idx_analytics_entity (entity_type, entity_id),

    -- Prevent duplicates
    UNIQUE(organization_id, event_type, event_date, entity_type, entity_id)
);

-- Materialized view for performance optimization
CREATE MATERIALIZED VIEW daily_lead_metrics AS
SELECT
    organization_id,
    DATE(created_at) as metric_date,
    AVG(lead_score) as avg_score,
    COUNT(*) as total_leads,
    COUNT(CASE WHEN stage = 'fechado' THEN 1 END) as closed_leads,
    AVG(CASE WHEN stage = 'fechado' THEN lead_score END) as avg_closed_score
FROM leads
GROUP BY organization_id, DATE(created_at);

CREATE INDEX idx_daily_metrics_org_date ON daily_lead_metrics(organization_id, metric_date);
```

### 2. Backend Implementation

**Core Service: LeadAnalyticsService**

```python
# api/services/crm_lead_analytics_service.py
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Dict, List, Optional
from uuid import UUID

from sqlalchemy import func, and_, case, extract, text
from sqlalchemy.orm import Session

from ..models.crm_lead import Lead, PipelineStage
from ..models.lead_behavior_tracking import LeadBehaviorTracking
from ..models.analytics_events import AnalyticsEvents
from ..models.crm_audit_log import AuditLog
from ..services.crm_lead_scoring_service import LeadScoringService

class LeadAnalyticsService:
    """Advanced lead analytics with organization isolation."""

    def __init__(self, db: Session):
        self.db = db
        self.scoring_service = LeadScoringService(db)

    async def calculate_executive_dashboard(
        self,
        organization_id: UUID,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        filters: Optional[Dict] = None
    ) -> Dict:
        """Calculate executive dashboard metrics leveraging Story 3.1 foundation."""

        # Default to last 30 days
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()

        # Base query with organization isolation
        base_query = self.db.query(Lead).filter(
            Lead.organization_id == organization_id,
            Lead.created_at >= start_date,
            Lead.created_at <= end_date
        )

        # Apply advanced filters
        if filters:
            if filters.get('source'):
                base_query = base_query.filter(Lead.source.in_(filters['source']))
            if filters.get('score_min'):
                base_query = base_query.filter(Lead.lead_score >= filters['score_min'])
            if filters.get('score_max'):
                base_query = base_query.filter(Lead.lead_score <= filters['score_max'])
            if filters.get('assigned_user_id'):
                base_query = base_query.filter(Lead.assigned_user_id == filters['assigned_user_id'])

        # 1. Summary metrics with growth calculation
        total_leads = base_query.count()
        previous_period_leads = await self._get_previous_period_count(organization_id, start_date, end_date)
        leads_growth = self._calculate_growth_percentage(total_leads, previous_period_leads)

        # 2. Average score leveraging Story 3.1 scoring
        avg_score_result = base_query.with_entities(func.avg(Lead.lead_score)).scalar()
        avg_score = float(avg_score_result) if avg_score_result else 0.0
        previous_avg_score = await self._get_previous_period_avg_score(organization_id, start_date, end_date)
        score_trend = avg_score - previous_avg_score

        # 3. Conversion funnel analysis
        funnel_data = await self._calculate_conversion_funnel(base_query)

        # 4. Score distribution using Story 3.1 factors
        score_distribution = await self._calculate_score_distribution(base_query)

        # 5. Performance by source with ROI analysis
        source_performance = await self._calculate_source_performance(base_query)

        # 6. Stage timing analysis using audit logs
        stage_timing = await self._calculate_stage_timing_analysis(organization_id, start_date, end_date)

        # 7. Behavioral insights
        behavior_insights = await self._calculate_behavior_insights(organization_id, start_date, end_date)

        # 8. Smart alerts generation
        alerts = await self._generate_performance_alerts(organization_id)

        return {
            "summary_metrics": {
                "total_leads": total_leads,
                "leads_growth_percentage": leads_growth,
                "average_score": round(avg_score, 1),
                "score_trend": round(score_trend, 1),
                "conversion_rate": funnel_data["overall_conversion_rate"],
                "period": {"start": start_date.isoformat(), "end": end_date.isoformat()}
            },
            "conversion_funnel": funnel_data,
            "score_distribution": score_distribution,
            "source_performance": source_performance,
            "stage_timing": stage_timing,
            "behavior_insights": behavior_insights,
            "alerts": alerts
        }

    async def _calculate_conversion_funnel(self, base_query) -> Dict:
        """Calculate detailed conversion funnel with Story 3.1 score correlation."""

        # Optimized query using CTEs for performance
        funnel_query = text("""
            WITH stage_analysis AS (
                SELECT
                    stage,
                    COUNT(*) as stage_count,
                    AVG(lead_score) as avg_score,
                    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY lead_score) as median_score,
                    AVG(EXTRACT(EPOCH FROM (updated_at - created_at))/86400) as avg_days_in_stage
                FROM leads
                WHERE organization_id = :org_id
                  AND created_at >= :start_date
                  AND created_at <= :end_date
                GROUP BY stage
            ),
            conversion_rates AS (
                SELECT
                    stage,
                    stage_count,
                    avg_score,
                    median_score,
                    avg_days_in_stage,
                    LAG(stage_count) OVER (ORDER BY
                        CASE stage
                            WHEN 'lead' THEN 1
                            WHEN 'contato' THEN 2
                            WHEN 'proposta' THEN 3
                            WHEN 'negociacao' THEN 4
                            WHEN 'fechado' THEN 5
                        END
                    ) as prev_stage_count
                FROM stage_analysis
            )
            SELECT
                stage,
                stage_count,
                ROUND(avg_score::NUMERIC, 1) as avg_score,
                ROUND(median_score::NUMERIC, 1) as median_score,
                ROUND(avg_days_in_stage::NUMERIC, 1) as avg_days_in_stage,
                CASE
                    WHEN prev_stage_count > 0
                    THEN ROUND((stage_count::FLOAT / prev_stage_count::FLOAT) * 100, 2)
                    ELSE 100.0
                END as conversion_rate
            FROM conversion_rates
            ORDER BY
                CASE stage
                    WHEN 'lead' THEN 1
                    WHEN 'contato' THEN 2
                    WHEN 'proposta' THEN 3
                    WHEN 'negociacao' THEN 4
                    WHEN 'fechado' THEN 5
                END;
        """)

        result = self.db.execute(funnel_query, {
            "org_id": str(organization_id),
            "start_date": start_date,
            "end_date": end_date
        })

        # Process results into funnel format
        stages_data = {}
        total_leads = 0
        closed_leads = 0

        for row in result:
            stage_info = {
                "count": row.stage_count,
                "avg_score": float(row.avg_score or 0),
                "median_score": float(row.median_score or 0),
                "avg_days": float(row.avg_days_in_stage or 0),
                "conversion_rate": float(row.conversion_rate or 0)
            }
            stages_data[row.stage] = stage_info

            if row.stage == 'lead':
                total_leads = row.stage_count
            elif row.stage == 'fechado':
                closed_leads = row.stage_count

        # Calculate overall conversion rate
        overall_conversion = round((closed_leads / total_leads * 100), 2) if total_leads > 0 else 0

        # Calculate bottleneck detection
        bottleneck_stage = self._detect_conversion_bottleneck(stages_data)

        return {
            "stages": stages_data,
            "overall_conversion_rate": overall_conversion,
            "total_leads_in_funnel": total_leads,
            "closed_leads": closed_leads,
            "bottleneck_stage": bottleneck_stage,
            "funnel_health": self._calculate_funnel_health(stages_data)
        }

    async def _generate_performance_alerts(self, organization_id: UUID) -> List[Dict]:
        """Generate smart alerts with actionable recommendations using Story 3.1 data."""

        alerts = []

        # Alert 1: Conversion rate drop detection
        recent_conversion = await self._get_recent_conversion_rate(organization_id, days=7)
        historical_conversion = await self._get_historical_conversion_rate(organization_id, days=30)

        if historical_conversion > 0 and recent_conversion < historical_conversion * 0.7:  # 30% drop
            potential_revenue = await self._calculate_pipeline_value_at_risk(organization_id)

            alerts.append({
                "type": "conversion_drop",
                "priority": "high",
                "title": "Conversion Drop Detected",
                "description": f"Recent conversion rate ({recent_conversion:.1f}%) is 30% below historical average ({historical_conversion:.1f}%)",
                "impact": f"R$ {potential_revenue:,.0f} in potential revenue at risk",
                "recommended_actions": [
                    "Review template performance using A/B testing data",
                    "Analyze recent lost deals in proposal stage",
                    "Check sales team activity levels and capacity",
                    "Schedule process optimization meeting with top performers",
                    "Review lead scoring accuracy - may need recalibration"
                ],
                "data": {
                    "recent_rate": recent_conversion,
                    "historical_rate": historical_conversion,
                    "drop_percentage": round((1 - recent_conversion/historical_conversion) * 100, 1),
                    "revenue_at_risk": potential_revenue
                },
                "created_at": datetime.now().isoformat()
            })

        # Alert 2: High-value leads stagnation (leveraging Story 3.1 scoring)
        stagnant_high_value = await self._detect_stagnant_high_value_leads(organization_id)
        if stagnant_high_value["count"] > 0:
            alerts.append({
                "type": "opportunity",
                "priority": "medium",
                "title": "High-Score Leads Accumulating",
                "description": f"{stagnant_high_value['count']} leads with score 80+ waiting > 3 days in early stages",
                "impact": f"R$ {stagnant_high_value['total_value']:,.0f} in estimated value stagnating",
                "recommended_actions": [
                    "Prioritize immediate outreach to score 80+ leads",
                    f"Assign to top performer: {stagnant_high_value['top_performer']}",
                    "Use 'High-Value Prospect' template with personalization",
                    "Set up automated follow-up sequence for high-score leads",
                    "Consider lead scoring factors - these may be very qualified"
                ],
                "data": stagnant_high_value,
                "created_at": datetime.now().isoformat()
            })

        # Alert 3: Score distribution anomaly
        score_anomaly = await self._detect_score_distribution_anomaly(organization_id)
        if score_anomaly["is_anomaly"]:
            alerts.append({
                "type": "data_quality",
                "priority": "low",
                "title": "Lead Score Distribution Shift",
                "description": f"Unusual shift in score distribution: {score_anomaly['description']}",
                "impact": "Scoring accuracy may be affected, impacting prioritization",
                "recommended_actions": [
                    "Review recent lead sources for quality changes",
                    "Validate scoring algorithm with recent conversions",
                    "Check for data entry issues or process changes",
                    "Consider retraining scoring model with recent data"
                ],
                "data": score_anomaly,
                "created_at": datetime.now().isoformat()
            })

        return alerts
```

**Repository Layer with Performance Optimization:**

```python
# api/repositories/lead_analytics_repository.py
from typing import Dict, List, Optional
from uuid import UUID
from datetime import datetime, timedelta
from sqlalchemy import func, and_, case, text
from sqlalchemy.orm import Session

class LeadAnalyticsRepository:
    """Optimized analytics queries with caching support."""

    def __init__(self, db: Session):
        self.db = db

    def get_conversion_trends_optimized(
        self,
        organization_id: UUID,
        days: int = 30
    ) -> List[Dict]:
        """High-performance conversion trends using materialized views."""

        # Use materialized view for performance
        query = text("""
            SELECT
                metric_date,
                total_leads,
                closed_leads,
                avg_score,
                CASE WHEN total_leads > 0
                     THEN ROUND((closed_leads::FLOAT / total_leads::FLOAT) * 100, 2)
                     ELSE 0
                END as conversion_rate,
                LAG(closed_leads::FLOAT / NULLIF(total_leads::FLOAT, 0) * 100, 7) OVER (ORDER BY metric_date) as prev_week_rate
            FROM daily_lead_metrics
            WHERE organization_id = :org_id
              AND metric_date >= CURRENT_DATE - INTERVAL ':days days'
            ORDER BY metric_date;
        """)

        result = self.db.execute(query, {
            "org_id": str(organization_id),
            "days": days
        })

        return [
            {
                "date": row.metric_date.isoformat(),
                "total_leads": row.total_leads,
                "closed_leads": row.closed_leads,
                "avg_score": float(row.avg_score or 0),
                "conversion_rate": float(row.conversion_rate or 0),
                "trend": "up" if row.prev_week_rate and row.conversion_rate > row.prev_week_rate else "down"
            }
            for row in result
        ]

    def get_behavioral_segments(self, organization_id: UUID) -> Dict:
        """Segment leads by behavioral patterns."""

        query = text("""
            WITH behavioral_analysis AS (
                SELECT
                    l.id,
                    l.lead_score,
                    l.stage,
                    COALESCE(bt.engagement_score, 0) as engagement_score,
                    COALESCE(bt.interaction_count, 0) as interaction_count,
                    EXTRACT(EPOCH FROM (NOW() - l.created_at))/86400 as age_days,
                    CASE
                        WHEN l.lead_score >= 80 AND COALESCE(bt.engagement_score, 0) >= 70 THEN 'champion'
                        WHEN l.lead_score >= 60 AND COALESCE(bt.engagement_score, 0) >= 50 THEN 'promising'
                        WHEN l.lead_score < 40 AND COALESCE(bt.engagement_score, 0) < 30 THEN 'cold'
                        WHEN l.lead_score >= 70 AND COALESCE(bt.engagement_score, 0) < 30 THEN 'qualified_unengaged'
                        ELSE 'standard'
                    END as behavioral_segment
                FROM leads l
                LEFT JOIN lead_behavior_tracking bt ON l.id = bt.lead_id
                WHERE l.organization_id = :org_id
                  AND l.created_at >= CURRENT_DATE - INTERVAL '90 days'
            )
            SELECT
                behavioral_segment,
                COUNT(*) as lead_count,
                AVG(lead_score) as avg_score,
                AVG(engagement_score) as avg_engagement,
                ROUND(AVG(age_days), 1) as avg_age_days,
                COUNT(CASE WHEN stage = 'fechado' THEN 1 END) as closed_count
            FROM behavioral_analysis
            GROUP BY behavioral_segment
            ORDER BY avg_score DESC;
        """)

        result = self.db.execute(query, {"org_id": str(organization_id)})

        segments = {}
        total_leads = 0

        for row in result:
            segment_data = {
                "count": row.lead_count,
                "avg_score": round(float(row.avg_score or 0), 1),
                "avg_engagement": round(float(row.avg_engagement or 0), 1),
                "avg_age_days": float(row.avg_age_days or 0),
                "closed_count": row.closed_count,
                "conversion_rate": round((row.closed_count / row.lead_count * 100), 2) if row.lead_count > 0 else 0
            }
            segments[row.behavioral_segment] = segment_data
            total_leads += row.lead_count

        # Calculate percentages
        for segment in segments.values():
            segment["percentage"] = round((segment["count"] / total_leads * 100), 1) if total_leads > 0 else 0

        return {
            "segments": segments,
            "total_analyzed": total_leads,
            "analysis_period": "90 days"
        }
```

### 3. Frontend Implementation

**Executive Dashboard Component:**

```typescript
// components/crm/lead-analytics-dashboard.tsx
import React, { useState, useEffect } from 'react';
import { useQuery, useQueryClient } from '@tanstack/react-query';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { DatePickerWithRange } from '@/components/ui/date-range-picker';
import { LeadAnalyticsCharts } from './lead-analytics-charts';
import { PerformanceAlerts } from './performance-alerts';
import { BehaviorInsights } from './behavior-insights';
import { useOrgContext } from '@/hooks/use-org-context';
import { leadAnalyticsApi } from '@/services/lead-analytics';
import { format, subDays } from 'date-fns';
import { TrendingUp, TrendingDown, AlertTriangle, Target, Users, Award } from 'lucide-react';

interface AnalyticsFilters {
  source?: string[];
  score_min?: number;
  score_max?: number;
  assigned_user_id?: string;
}

export function LeadAnalyticsDashboard() {
  const { organization } = useOrgContext();
  const queryClient = useQueryClient();

  const [dateRange, setDateRange] = useState({
    from: subDays(new Date(), 30),
    to: new Date()
  });

  const [filters, setFilters] = useState<AnalyticsFilters>({});
  const [refreshInterval, setRefreshInterval] = useState(5 * 60 * 1000); // 5 minutes

  // Main analytics query with smart caching
  const {
    data: analyticsData,
    isLoading,
    error,
    refetch
  } = useQuery({
    queryKey: ['lead-analytics-executive', organization?.id, dateRange, filters],
    queryFn: () => leadAnalyticsApi.getExecutiveDashboard({
      organizationId: organization!.id,
      startDate: dateRange.from,
      endDate: dateRange.to,
      filters
    }),
    enabled: !!organization?.id,
    refetchInterval,
    staleTime: 2 * 60 * 1000, // 2 minutes stale time
    cacheTime: 10 * 60 * 1000, // 10 minutes cache time
  });

  // Auto-refresh with smart polling (slower when inactive)
  useEffect(() => {
    let interval = 5 * 60 * 1000; // 5 minutes default

    const handleVisibilityChange = () => {
      if (document.hidden) {
        interval = 15 * 60 * 1000; // 15 minutes when hidden
      } else {
        interval = 5 * 60 * 1000; // 5 minutes when active
      }
      setRefreshInterval(interval);
    };

    document.addEventListener('visibilitychange', handleVisibilityChange);
    return () => document.removeEventListener('visibilitychange', handleVisibilityChange);
  }, []);

  const handleFilterChange = (key: string, value: any) => {
    setFilters(prev => ({ ...prev, [key]: value }));
  };

  const clearFilters = () => {
    setFilters({});
    queryClient.invalidateQueries(['lead-analytics-executive']);
  };

  if (isLoading) {
    return <ExecutiveDashboardSkeleton />;
  }

  if (error || !analyticsData) {
    return <ErrorState error={error} onRetry={() => refetch()} />;
  }

  const { summary_metrics, conversion_funnel, alerts, behavior_insights } = analyticsData;

  return (
    <div className="space-y-6 p-6">
      {/* Header with Real-time Status */}
      <div className="flex items-center justify-between">
        <div>
          <h1 className="text-3xl font-bold tracking-tight">Lead Analytics</h1>
          <p className="text-muted-foreground">
            Performance insights for {organization?.name}
            <Badge variant="outline" className="ml-2">
              Last updated: {format(new Date(), 'HH:mm')}
            </Badge>
          </p>
        </div>

        <div className="flex items-center space-x-4">
          <DatePickerWithRange
            date={dateRange}
            onDateChange={setDateRange}
          />
          <Button variant="outline" onClick={() => refetch()}>
            Refresh Data
          </Button>
        </div>
      </div>

      {/* Advanced Filters */}
      <Card>
        <CardHeader>
          <CardTitle className="text-lg">Filters & Views</CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-1 md:grid-cols-4 gap-4">
            <Select onValueChange={(value) => handleFilterChange('source', [value])}>
              <SelectTrigger>
                <SelectValue placeholder="Filter by Source" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="linkedin">LinkedIn</SelectItem>
                <SelectItem value="google_ads">Google Ads</SelectItem>
                <SelectItem value="referral">Referral</SelectItem>
                <SelectItem value="direct">Direct</SelectItem>
                <SelectItem value="website">Website</SelectItem>
              </SelectContent>
            </Select>

            <Select onValueChange={(value) => handleFilterChange('score_min', parseInt(value))}>
              <SelectTrigger>
                <SelectValue placeholder="Min Score" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="0">All Scores</SelectItem>
                <SelectItem value="25">25+ (Fair)</SelectItem>
                <SelectItem value="50">50+ (Good)</SelectItem>
                <SelectItem value="75">75+ (Excellent)</SelectItem>
              </SelectContent>
            </Select>

            <div className="flex items-center space-x-2">
              <Badge variant="secondary">{Object.keys(filters).length} filters active</Badge>
              {Object.keys(filters).length > 0 && (
                <Button variant="ghost" size="sm" onClick={clearFilters}>
                  Clear All
                </Button>
              )}
            </div>
          </div>
        </CardContent>
      </Card>

      {/* Performance Alerts - Priority Display */}
      {alerts && alerts.length > 0 && (
        <PerformanceAlerts alerts={alerts} />
      )}

      {/* Executive Summary Cards */}
      <div className="grid gap-4 md:grid-cols-4">
        <SummaryCard
          title="Total Leads"
          value={summary_metrics.total_leads.toLocaleString()}
          change={summary_metrics.leads_growth_percentage}
          icon={<Users className="h-4 w-4" />}
          description={`From ${format(dateRange.from, 'MMM dd')} to ${format(dateRange.to, 'MMM dd')}`}
        />

        <SummaryCard
          title="Avg Lead Score"
          value={summary_metrics.average_score.toString()}
          change={summary_metrics.score_trend}
          icon={<Award className="h-4 w-4" />}
          description="6-factor ML scoring average"
        />

        <SummaryCard
          title="Conversion Rate"
          value={`${summary_metrics.conversion_rate}%`}
          icon={<Target className="h-4 w-4" />}
          description="Lead → Closed conversion"
        />

        <SummaryCard
          title="Pipeline Health"
          value={conversion_funnel.funnel_health || "Good"}
          icon={<TrendingUp className="h-4 w-4" />}
          description="Overall funnel performance"
        />
      </div>

      {/* Main Analytics Charts */}
      <LeadAnalyticsCharts
        conversionFunnel={conversion_funnel}
        scoreDistribution={analyticsData.score_distribution}
        sourcePerformance={analyticsData.source_performance}
        stageTiming={analyticsData.stage_timing}
      />

      {/* Behavioral Insights */}
      <BehaviorInsights insights={behavior_insights} />
    </div>
  );
}

// Summary card with trend indicators
function SummaryCard({
  title,
  value,
  change,
  icon,
  description
}: {
  title: string;
  value: string;
  change?: number;
  icon: React.ReactNode;
  description: string;
}) {
  return (
    <Card>
      <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
        <CardTitle className="text-sm font-medium">{title}</CardTitle>
        <div className="flex items-center space-x-2">
          {icon}
          {change !== undefined && (
            <Badge
              variant={change > 0 ? "default" : change < 0 ? "destructive" : "secondary"}
              className="text-xs"
            >
              {change > 0 ? <TrendingUp className="h-3 w-3 mr-1" /> : change < 0 ? <TrendingDown className="h-3 w-3 mr-1" /> : null}
              {change > 0 ? '+' : ''}{change}%
            </Badge>
          )}
        </div>
      </CardHeader>
      <CardContent>
        <div className="text-2xl font-bold">{value}</div>
        <p className="text-xs text-muted-foreground">{description}</p>
      </CardContent>
    </Card>
  );
}

function ExecutiveDashboardSkeleton() {
  return (
    <div className="space-y-6 p-6">
      <div className="flex items-center justify-between">
        <div className="space-y-2">
          <div className="h-8 bg-muted rounded w-48 animate-pulse" />
          <div className="h-4 bg-muted rounded w-64 animate-pulse" />
        </div>
        <div className="flex space-x-4">
          <div className="h-10 bg-muted rounded w-48 animate-pulse" />
          <div className="h-10 bg-muted rounded w-24 animate-pulse" />
        </div>
      </div>

      <div className="grid gap-4 md:grid-cols-4">
        {Array.from({length: 4}).map((_, i) => (
          <Card key={i}>
            <CardHeader>
              <div className="h-4 bg-muted rounded animate-pulse" />
            </CardHeader>
            <CardContent>
              <div className="h-8 bg-muted rounded animate-pulse mb-2" />
              <div className="h-3 bg-muted rounded animate-pulse w-2/3" />
            </CardContent>
          </Card>
        ))}
      </div>

      <div className="grid gap-4 md:grid-cols-2">
        {Array.from({length: 4}).map((_, i) => (
          <Card key={i}>
            <CardContent className="p-6">
              <div className="h-64 bg-muted rounded animate-pulse" />
            </CardContent>
          </Card>
        ))}
      </div>
    </div>
  );
}
```

**Advanced Charts Component:**

```typescript
// components/crm/lead-analytics-charts.tsx
import React, { useMemo } from 'react';
import {
  BarChart, Bar, LineChart, Line, PieChart, Pie, Cell, FunnelChart,
  XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer,
  Area, AreaChart, ComposedChart
} from 'recharts';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { AlertTriangle, TrendingUp, Clock, Target } from 'lucide-react';

interface ChartsProps {
  conversionFunnel: any;
  scoreDistribution: any;
  sourcePerformance: any;
  stageTiming: any;
}

export function LeadAnalyticsCharts({
  conversionFunnel,
  scoreDistribution,
  sourcePerformance,
  stageTiming
}: ChartsProps) {

  // Prepare data for visualizations
  const funnelData = useMemo(() => {
    if (!conversionFunnel?.stages) return [];

    return Object.entries(conversionFunnel.stages).map(([stage, data]: [string, any]) => ({
      name: stage.charAt(0).toUpperCase() + stage.slice(1),
      leads: data.count,
      percentage: data.percentage || 0,
      avgScore: data.avg_score || 0,
      conversionRate: data.conversion_rate || 0,
      avgDays: data.avg_days || 0
    })).sort((a, b) => {
      const stageOrder = { 'Lead': 1, 'Contato': 2, 'Proposta': 3, 'Negociacao': 4, 'Fechado': 5 };
      return (stageOrder[a.name] || 6) - (stageOrder[b.name] || 6);
    });
  }, [conversionFunnel]);

  const scoreDistData = useMemo(() => {
    if (!scoreDistribution) return [];

    return [
      { name: '0-25 (Low)', value: scoreDistribution['0-25'] || 0, color: '#ef4444' },
      { name: '26-50 (Fair)', value: scoreDistribution['26-50'] || 0, color: '#f59e0b' },
      { name: '51-75 (Good)', value: scoreDistribution['51-75'] || 0, color: '#10b981' },
      { name: '76-100 (Excellent)', value: scoreDistribution['76-100'] || 0, color: '#8b5cf6' }
    ];
  }, [scoreDistribution]);

  const COLORS = ['#8b5cf6', '#10b981', '#f59e0b', '#ef4444', '#06b6d4'];

  return (
    <div className="grid gap-6">
      {/* Conversion Funnel - Full Width */}
      <Card className="col-span-full">
        <CardHeader>
          <div className="flex items-center justify-between">
            <div>
              <CardTitle className="flex items-center gap-2">
                <Target className="h-5 w-5" />
                Conversion Funnel Analysis
              </CardTitle>
              <CardDescription>
                Lead progression with score correlation and timing analysis
              </CardDescription>
            </div>
            {conversionFunnel?.bottleneck_stage && (
              <Badge variant="destructive" className="gap-1">
                <AlertTriangle className="h-3 w-3" />
                Bottleneck: {conversionFunnel.bottleneck_stage}
              </Badge>
            )}
          </div>
        </CardHeader>
        <CardContent>
          {/* Funnel Chart */}
          <div className="h-80 mb-6">
            <ResponsiveContainer width="100%" height="100%">
              <ComposedChart data={funnelData} margin={{ top: 20, right: 30, left: 20, bottom: 5 }}>
                <CartesianGrid strokeDasharray="3 3" />
                <XAxis dataKey="name" />
                <YAxis yAxisId="left" />
                <YAxis yAxisId="right" orientation="right" />
                <Tooltip
                  formatter={(value, name, props) => {
                    if (name === 'Leads Count') return [`${value} leads`, name];
                    if (name === 'Avg Score') return [`${value} points`, name];
                    if (name === 'Conversion Rate') return [`${value}%`, name];
                    return [value, name];
                  }}
                />
                <Legend />
                <Bar yAxisId="left" dataKey="leads" fill="#8b5cf6" name="Leads Count" />
                <Line yAxisId="right" type="monotone" dataKey="avgScore" stroke="#10b981" strokeWidth={3} name="Avg Score" />
                <Line yAxisId="right" type="monotone" dataKey="conversionRate" stroke="#f59e0b" strokeWidth={2} name="Conversion Rate" />
              </ComposedChart>
            </ResponsiveContainer>
          </div>

          {/* Funnel Metrics Grid */}
          <div className="grid grid-cols-1 md:grid-cols-5 gap-4">
            {funnelData.map((stage, index) => (
              <div key={stage.name} className="text-center p-4 border rounded-lg">
                <div className="text-sm font-medium text-muted-foreground mb-1">{stage.name}</div>
                <div className="text-2xl font-bold mb-2">{stage.leads.toLocaleString()}</div>
                <div className="text-xs text-muted-foreground mb-2">
                  {stage.percentage.toFixed(1)}% of total
                </div>
                <div className="space-y-1">
                  <Badge variant="outline" className="text-xs">
                    Score: {stage.avgScore.toFixed(1)}
                  </Badge>
                  <Badge variant="secondary" className="text-xs block">
                    {stage.avgDays.toFixed(1)} days avg
                  </Badge>
                  {stage.conversionRate > 0 && (
                    <Badge variant="default" className="text-xs block">
                      {stage.conversionRate.toFixed(1)}% conversion
                    </Badge>
                  )}
                </div>
              </div>
            ))}
          </div>

          {/* Funnel Health Indicator */}
          <div className="mt-4 p-4 bg-muted/50 rounded-lg">
            <div className="flex items-center justify-between mb-2">
              <span className="text-sm font-medium">Overall Funnel Health</span>
              <Badge variant={conversionFunnel?.funnel_health === 'Good' ? 'default' : 'secondary'}>
                {conversionFunnel?.funnel_health || 'Unknown'}
              </Badge>
            </div>
            <Progress
              value={conversionFunnel?.overall_conversion_rate || 0}
              className="h-2"
              max={30} // 30% is excellent conversion rate
            />
            <div className="text-xs text-muted-foreground mt-1">
              {conversionFunnel?.overall_conversion_rate?.toFixed(1)}% overall conversion rate
              ({conversionFunnel?.closed_leads || 0} closed from {conversionFunnel?.total_leads_in_funnel || 0} total)
            </div>
          </div>
        </CardContent>
      </Card>

      {/* Score Distribution & Performance Grid */}
      <div className="grid gap-6 md:grid-cols-2">
        {/* Score Distribution Pie Chart */}
        <Card>
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <TrendingUp className="h-4 w-4" />
              Lead Quality Distribution
            </CardTitle>
            <CardDescription>
              Breakdown by ML scoring ranges (Story 3.1 integration)
            </CardDescription>
          </CardHeader>
          <CardContent>
            <div className="h-64">
              <ResponsiveContainer width="100%" height="100%">
                <PieChart>
                  <Pie
                    data={scoreDistData}
                    cx="50%"
                    cy="50%"
                    labelLine={false}
                    label={({ name, value, percent }) =>
                      value > 0 ? `${name}: ${(percent * 100).toFixed(0)}%` : ''
                    }
                    outerRadius={80}
                    fill="#8884d8"
                    dataKey="value"
                  >
                    {scoreDistData.map((entry, index) => (
                      <Cell key={`cell-${index}`} fill={entry.color} />
                    ))}
                  </Pie>
                  <Tooltip formatter={(value) => [`${value} leads`, 'Count']} />
                </PieChart>
              </ResponsiveContainer>
            </div>

            {/* Score insights */}
            <div className="mt-4 space-y-2">
              {scoreDistData.map((segment, index) => (
                <div key={segment.name} className="flex items-center justify-between text-sm">
                  <div className="flex items-center gap-2">
                    <div
                      className="w-3 h-3 rounded-full"
                      style={{ backgroundColor: segment.color }}
                    />
                    <span>{segment.name}</span>
                  </div>
                  <span className="font-medium">{segment.value} leads</span>
                </div>
              ))}
            </div>
          </CardContent>
        </Card>

        {/* Source Performance */}
        <Card>
          <CardHeader>
            <CardTitle>Performance by Source</CardTitle>
            <CardDescription>
              Conversion rates and ROI by lead origin
            </CardDescription>
          </CardHeader>
          <CardContent>
            <div className="h-64">
              <ResponsiveContainer width="100%" height="100%">
                <BarChart
                  data={sourcePerformance || []}
                  margin={{ top: 20, right: 30, left: 20, bottom: 5 }}
                >
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis
                    dataKey="source"
                    angle={-45}
                    textAnchor="end"
                    height={80}
                  />
                  <YAxis />
                  <Tooltip
                    formatter={(value, name) => [
                      `${value}%`,
                      name === 'conversion_rate' ? 'Conversion Rate' : name
                    ]}
                  />
                  <Bar
                    dataKey="conversion_rate"
                    fill="#10b981"
                    radius={[4, 4, 0, 0]}
                  />
                </BarChart>
              </ResponsiveContainer>
            </div>
          </CardContent>
        </Card>
      </div>

      {/* Stage Timing Analysis */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center gap-2">
            <Clock className="h-4 w-4" />
            Stage Timing Analysis
          </CardTitle>
          <CardDescription>
            Average time spent in each pipeline stage
          </CardDescription>
        </CardHeader>
        <CardContent>
          {stageTiming && (
            <div className="space-y-4">
              {Object.entries(stageTiming).map(([stage, timing]: [string, any]) => (
                <div key={stage} className="flex items-center justify-between p-3 border rounded-lg">
                  <div>
                    <div className="font-medium capitalize">{stage} Stage</div>
                    <div className="text-sm text-muted-foreground">
                      Average: {timing.avg_days || 0} days
                    </div>
                  </div>
                  <div className="text-right">
                    <div className="text-lg font-bold">
                      {timing.lead_count || 0} leads
                    </div>
                    <Badge variant={timing.avg_days > 7 ? 'destructive' : 'default'}>
                      {timing.avg_days > 7 ? 'Slow' : 'Good'}
                    </Badge>
                  </div>
                </div>
              ))}
            </div>
          )}
        </CardContent>
      </Card>
    </div>
  );
}
```

### 4. API Router Implementation

```python
# api/routers/crm_analytics.py
from datetime import datetime, date
from typing import Dict, List, Optional
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.orm import Session

from ..core.deps import get_current_organization, get_db, get_current_user
from ..models.organization import Organization
from ..models.user import User
from ..services.crm_lead_analytics_service import LeadAnalyticsService
from ..schemas.analytics import (
    ExecutiveDashboardResponse,
    AnalyticsFilters,
    BehaviorAnalysisResponse,
    ReportGenerationRequest
)

router = APIRouter(prefix="/crm/analytics", tags=["Lead Analytics"])

@router.get("/executive-dashboard")
async def get_executive_dashboard(
    start_date: Optional[datetime] = Query(None, description="Start date for analytics period"),
    end_date: Optional[datetime] = Query(None, description="End date for analytics period"),
    source: Optional[List[str]] = Query(None, description="Filter by lead sources"),
    score_min: Optional[float] = Query(None, ge=0, le=100, description="Minimum lead score"),
    score_max: Optional[float] = Query(None, ge=0, le=100, description="Maximum lead score"),
    assigned_user_id: Optional[UUID] = Query(None, description="Filter by assigned user"),
    organization: Organization = Depends(get_current_organization),
    db: Session = Depends(get_db)
):
    """
    Get comprehensive executive analytics dashboard.

    Leverages Story 3.1 foundation (scoring, deduplication, assignment) to provide
    actionable business intelligence including conversion funnels, behavioral insights,
    and smart performance alerts.

    Features:
    - Real-time metrics with growth trends
    - ML-powered conversion funnel analysis
    - Lead quality distribution using Story 3.1 scoring
    - Source performance with ROI analysis
    - Smart alerts with recommended actions
    - Organization isolation for multi-tenancy
    """

    analytics_service = LeadAnalyticsService(db)

    # Build filters dictionary
    filters = {}
    if source:
        filters['source'] = source
    if score_min is not None:
        filters['score_min'] = score_min
    if score_max is not None:
        filters['score_max'] = score_max
    if assigned_user_id:
        filters['assigned_user_id'] = assigned_user_id

    try:
        dashboard_data = await analytics_service.calculate_executive_dashboard(
            organization_id=organization.id,
            start_date=start_date,
            end_date=end_date,
            filters=filters if filters else None
        )

        return {
            "success": True,
            "data": dashboard_data,
            "organization": {
                "id": str(organization.id),
                "name": organization.name
            },
            "generated_at": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Analytics calculation failed",
                "message": str(e),
                "organization_id": str(organization.id)
            }
        )

@router.get("/behavior-analysis")
async def get_behavior_analysis(
    lead_id: Optional[UUID] = Query(None, description="Specific lead ID for detailed analysis"),
    segment: Optional[str] = Query(None, description="Behavioral segment filter"),
    days: int = Query(30, ge=1, le=365, description="Analysis period in days"),
    organization: Organization = Depends(get_current_organization),
    db: Session = Depends(get_db)
):
    """
    Get detailed behavioral analysis and lead segmentation.

    Analyzes lead interaction patterns, engagement scores, and behavioral segments
    to provide insights for personalized outreach and conversion optimization.
    """

    analytics_service = LeadAnalyticsService(db)

    try:
        behavior_data = await analytics_service.get_behavior_analysis(
            organization_id=organization.id,
            lead_id=lead_id,
            segment=segment,
            days=days
        )

        return {
            "success": True,
            "data": behavior_data,
            "analysis_period": f"{days} days",
            "generated_at": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Behavior analysis failed",
                "message": str(e)
            }
        )

@router.post("/generate-report")
async def generate_analytics_report(
    background_tasks: BackgroundTasks,
    report_type: str = Query(..., regex="^(pdf|excel)$", description="Report format: pdf or excel"),
    filters: Optional[AnalyticsFilters] = None,
    include_charts: bool = Query(True, description="Include visualizations in report"),
    organization: Organization = Depends(get_current_organization),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Generate comprehensive analytics report (PDF or Excel).

    Creates detailed reports with executive summary, conversion analysis,
    behavioral insights, and actionable recommendations. Reports are
    organization-branded and can be shared with stakeholders.
    """

    analytics_service = LeadAnalyticsService(db)

    try:
        # Trigger background report generation
        background_tasks.add_task(
            analytics_service.generate_report_async,
            organization_id=organization.id,
            user_id=current_user.id,
            report_type=report_type,
            filters=filters.dict() if filters else None,
            include_charts=include_charts
        )

        return {
            "success": True,
            "message": f"Analytics report generation started",
            "report_type": report_type,
            "estimated_completion": "2-5 minutes",
            "organization": organization.name,
            "requested_by": current_user.email
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Report generation failed",
                "message": str(e)
            }
        )

@router.get("/alerts")
async def get_performance_alerts(
    priority: Optional[str] = Query(None, regex="^(high|medium|low)$"),
    alert_type: Optional[str] = Query(None, description="Filter by alert type"),
    limit: int = Query(10, ge=1, le=50, description="Number of alerts to return"),
    organization: Organization = Depends(get_current_organization),
    db: Session = Depends(get_db)
):
    """
    Get smart performance alerts with recommended actions.

    Returns intelligent alerts about conversion drops, stagnant high-value leads,
    score distribution anomalies, and other performance issues with specific
    recommended actions for improvement.
    """

    analytics_service = LeadAnalyticsService(db)

    try:
        alerts = await analytics_service.get_performance_alerts(
            organization_id=organization.id,
            priority_filter=priority,
            alert_type_filter=alert_type,
            limit=limit
        )

        return {
            "success": True,
            "alerts": alerts,
            "total_count": len(alerts),
            "organization": organization.name,
            "generated_at": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Alerts retrieval failed",
                "message": str(e)
            }
        )

@router.put("/alerts/{alert_id}/status")
async def update_alert_status(
    alert_id: UUID,
    status: str = Query(..., regex="^(reviewed|dismissed|resolved)$"),
    notes: Optional[str] = None,
    organization: Organization = Depends(get_current_organization),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Update alert status with user tracking."""

    analytics_service = LeadAnalyticsService(db)

    try:
        result = await analytics_service.update_alert_status(
            organization_id=organization.id,
            alert_id=alert_id,
            status=status,
            notes=notes,
            user_id=current_user.id
        )

        return {
            "success": True,
            "message": f"Alert {status} successfully",
            "alert_id": str(alert_id),
            "updated_by": current_user.email
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Alert status update failed",
                "message": str(e)
            }
        )

# Health check endpoint for analytics system
@router.get("/health")
async def analytics_health_check(
    organization: Organization = Depends(get_current_organization),
    db: Session = Depends(get_db)
):
    """Check analytics system health and data freshness."""

    analytics_service = LeadAnalyticsService(db)

    try:
        health_status = await analytics_service.check_system_health(organization.id)

        return {
            "success": True,
            "status": "healthy",
            "data_freshness": health_status["data_freshness"],
            "query_performance": health_status["avg_query_time"],
            "cache_hit_rate": health_status["cache_hit_rate"],
            "last_update": health_status["last_update"]
        }

    except Exception as e:
        return {
            "success": False,
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
```

### 5. Risk Mitigation Implementation

**Performance Monitoring:**

```python
# api/core/analytics_monitoring.py
import time
import structlog
from functools import wraps
from typing import Dict, Any

logger = structlog.get_logger()

def monitor_analytics_performance(func):
    """Decorator to monitor analytics function performance."""

    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        function_name = func.__name__

        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start_time

            # Log performance metrics
            logger.info(
                "analytics_performance",
                function=function_name,
                duration_ms=duration * 1000,
                organization_id=kwargs.get('organization_id'),
                result_size=len(result) if isinstance(result, (list, dict)) else 1,
                success=True
            )

            # Performance alert if slow
            if duration > 1.0:  # 1 second threshold
                logger.warning(
                    "slow_analytics_query",
                    function=function_name,
                    duration_ms=duration * 1000,
                    threshold_exceeded=True
                )

            return result

        except Exception as e:
            duration = time.time() - start_time

            logger.error(
                "analytics_error",
                function=function_name,
                duration_ms=duration * 1000,
                error=str(e),
                error_type=type(e).__name__,
                organization_id=kwargs.get('organization_id'),
                success=False
            )

            # Re-raise the exception
            raise

    return wrapper

class AnalyticsCache:
    """Redis-based caching for analytics queries."""

    def __init__(self, redis_client):
        self.redis = redis_client
        self.default_ttl = 300  # 5 minutes

    def get_cache_key(self, org_id: str, query_type: str, params: Dict[str, Any]) -> str:
        """Generate cache key for analytics query."""
        params_str = "|".join(f"{k}:{v}" for k, v in sorted(params.items()))
        return f"analytics:{org_id}:{query_type}:{hash(params_str)}"

    async def get_cached_result(self, cache_key: str):
        """Get cached analytics result."""
        try:
            cached = await self.redis.get(cache_key)
            if cached:
                return json.loads(cached)
        except Exception as e:
            logger.warning("cache_get_failed", key=cache_key, error=str(e))
        return None

    async def cache_result(self, cache_key: str, result: Any, ttl: int = None):
        """Cache analytics result with TTL."""
        try:
            ttl = ttl or self.default_ttl
            await self.redis.setex(
                cache_key,
                ttl,
                json.dumps(result, default=str)
            )
        except Exception as e:
            logger.warning("cache_set_failed", key=cache_key, error=str(e))
```

## Implementation Plan

### Phase 1: Backend Foundation (2 days)

**Day 1:**

- [ ] Database migrations: `lead_behavior_tracking`, `analytics_events`, materialized view
- [ ] `LeadAnalyticsService` core implementation with organization isolation
- [ ] `LeadAnalyticsRepository` with optimized queries
- [ ] Unit tests for analytics calculations

**Day 2:**

- [ ] API routes implementation with proper error handling
- [ ] Performance monitoring and caching integration
- [ ] Smart alerts generation system
- [ ] Integration tests with Story 3.1 services

### Phase 2: Frontend Implementation (2 days)

**Day 3:**

- [ ] Executive dashboard component with real-time updates
- [ ] Advanced charts using Recharts with performance optimization
- [ ] Performance alerts UI with actionable recommendations
- [ ] Filter system with smart defaults

**Day 4:**

- [ ] Behavioral insights visualization
- [ ] Report generation UI with progress tracking
- [ ] Mobile responsive optimization
- [ ] Loading states and error handling

### Phase 3: Integration & Polish (1 day)

**Day 5:**

- [ ] End-to-end integration testing
- [ ] Performance optimization and caching validation
- [ ] Documentation and API specifications
- [ ] Stakeholder demo preparation

## Acceptance Criteria

### Technical Requirements:

- [ ] ✅ Executive dashboard loads < 2 seconds (95th percentile)
- [ ] ✅ Database queries execute < 500ms with proper caching
- [ ] ✅ 100% organization isolation validated in all analytics queries
- [ ] ✅ Smart alerts system with 5+ actionable recommendations
- [ ] ✅ Mobile responsive design with touch optimization

### Business Requirements:

- [ ] ✅ CFO can identify R$ 200k+ pipeline bottlenecks with specific stages
- [ ] ✅ Conversion funnel shows correlation with Story 3.1 ML scoring
- [ ] ✅ Performance alerts include recommended actions with estimated impact
- [ ] ✅ Behavioral segmentation identifies high-value opportunity leads
- [ ] ✅ Report generation (PDF/Excel) with organization branding

### Integration Requirements:

- [ ] ✅ Leverages existing Story 3.1 scoring service without modifications
- [ ] ✅ Uses existing audit logs for stage transition analysis
- [ ] ✅ Maintains compatibility with pipeline kanban real-time updates
- [ ] ✅ Respects existing multi-tenancy architecture patterns
- [ ] ✅ Integrates with existing organization context and permissions

## Success Metrics

**Performance KPIs:**

- Dashboard load time: < 2 seconds
- Query performance: < 500ms (95th percentile)
- Cache hit ratio: > 80%
- Error rate: < 0.1%

**Business Impact:**

- Executive decision time reduction: 60%
- Lead prioritization accuracy: 85%+
- Sales team efficiency: +25%
- Revenue opportunity identification: 95%+ high-value lead capture

## Conclusion

**Story 3.2** successfully bridges the gap between the technical foundation of Story 3.1 and the UX polish of Story 3.3 by providing a comprehensive analytics intelligence layer. The implementation leverages existing services, maintains perfect organization isolation, and delivers actionable business intelligence that enables data-driven decision making for improved sales performance and revenue optimization.

The solution is architected for scalability, performance, and maintainability while providing immediate business value through executive dashboards, smart alerts, and behavioral insights that directly support the strategic objectives of the LovedCRM platform.
